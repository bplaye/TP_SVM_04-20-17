{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016-11-25: Support Vector Machines\n",
    "This page is the practical session of the \"Support Vector Machines\" module taught by Jean-Philippe Vert (LIEN). The lecture slides can be found here (LIEN).\n",
    "\n",
    "This work is inspired from the SVM-lab of Centrale course taught by Chloé-Agathe Azencott etc etc \n",
    "\n",
    "We will apply support vector classification methods to various datasets. \n",
    "\n",
    "Let us start, by setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear case: separable case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the corresponding data\n",
    "X_train = \n",
    "X_test = \n",
    "Y_train =\n",
    "Y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with default C value\n",
    "\n",
    "Let us fit an SVM with linear kernel (linear soft-margin SVM) with default C parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(X_train,Y_train)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "## TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of support vectors\n",
    "\n",
    "The `n_support_` argument of an svm classifier gives us the number of support vectors for each class.\n",
    "\n",
    "**Question:** How many support vectors does our classifier have? How many is this compared to the number of training samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating hyperplane\n",
    "\n",
    "Let us plot the separating hyperplan and visualize its support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data_with_hyperplane(xx,yy,clf):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(-5, 5)\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "    # plot the parallels to the separating hyperplane that pass through the\n",
    "    # support vectors\n",
    "    b = clf.support_vectors_[0]\n",
    "    yy_down = a * xx + (b[1] - a * b[0])\n",
    "    b = clf.support_vectors_[-1]\n",
    "    yy_up = a * xx + (b[1] - a * b[0])\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.plot(xx, yy, 'k-')\n",
    "    plt.plot(xx, yy_down, 'k--')\n",
    "    plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "    plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
    "                s=80, facecolors='none')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_with_hyperplane(X,Y,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM: non separable case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the corresponding data\n",
    "X_train = \n",
    "X_test = \n",
    "Y_train =\n",
    "Y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with default C value\n",
    "\n",
    "Let us fit an SVM with linear kernel and default C parameter. Print the accuracy and plot the hyperplan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## copier coller code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "**Question:** Plot the distribution of samples. Comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with cross-validated C value\n",
    "\n",
    "Let us cross-validate an SVM with linear kernel (linear soft-margin SVM) to find the optimal C parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Complete the following cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(design_matrix, labels, classifier, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns, for each data point x, \n",
    "    the value of the decision function f computed when x was part of the test set. \n",
    "   \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  sklearn classifier object\n",
    "        Classifier instance; must have the following methods:\n",
    "        - fit(X, y) to train the classifier on the data X, y\n",
    "        - decision_function(X) to apply the trained classifier to the data X \n",
    "        and return probability estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape) # Hold all predictions, in correct order.\n",
    "    for tr, te in cv_folds:\n",
    "        # Restrict data to train/test folds\n",
    "        Xtr = design_matrix[tr, :]\n",
    "        ytr = labels[tr]\n",
    "        Xte = design_matrix[te, :]\n",
    "        \n",
    "        # Fit classifier\n",
    "        classifier.fit(Xtr, ytr)\n",
    "\n",
    "        # Compute decision function on test data\n",
    "        # TODO \n",
    "        \n",
    "        # Update pred \n",
    "        # TODO \n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find the optimal C parameter via cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** print the accuracy and plot the data with the hyperplance corresponding to the fitted SVM and compare with those of SVM with default C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code avec des TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with cross-validated C value (Bonus)\n",
    "\n",
    "parler de la fonction grid search CV et leur demander coder la même chose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code avec TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non linear case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the corresponding data\n",
    "X_train = \n",
    "X_test = \n",
    "Y_train =\n",
    "Y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demander à tester différent kernel en utilisant C manuellement (pour voir l'effet de C sur le separating hyperplane) puis print accuracy avec un C optimisé par crossCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A real case: blabla\n",
    "\n",
    "Expliquer l'origine des données etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the corresponding data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the data by pca (??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquer en quoi consister scaler ou normaliser les données et parler de son interêt\n",
    "\n",
    "**Question:** Complete the following cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize an SVM approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "à eux de jouer blabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
